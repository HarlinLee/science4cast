{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "node_embedding_any_year.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Environment (conda_tensorflow_p37)",
      "language": "python",
      "name": "conda_tensorflow_p37"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "774529fa0ee744e6b39504440df958be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ae77d3998bf41919fdde0a6afdb2323",
              "IPY_MODEL_d915287d2fa742389059fffeab010973",
              "IPY_MODEL_bb8f72ff25504aa09b916d4525ceab6d"
            ],
            "layout": "IPY_MODEL_658bcdf1c13a481991d346af63320c0f"
          }
        },
        "6ae77d3998bf41919fdde0a6afdb2323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd27cb56576545a8b5a43bc6f2f8d71d",
            "placeholder": "​",
            "style": "IPY_MODEL_e2b468150f45450e97a9812a9eaac915",
            "value": "Validation sanity check:   0%"
          }
        },
        "d915287d2fa742389059fffeab010973": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65aa6394197e4ee18c4c23ded8d8713d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb07957144c14ef899cb42e19c9082c4",
            "value": 0
          }
        },
        "bb8f72ff25504aa09b916d4525ceab6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c460a5008ed4503b1476e512f6146d9",
            "placeholder": "​",
            "style": "IPY_MODEL_49e2ef477bb94d0c95a500b035f37fad",
            "value": " 0/2 [00:01&lt;?, ?it/s]"
          }
        },
        "658bcdf1c13a481991d346af63320c0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "dd27cb56576545a8b5a43bc6f2f8d71d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2b468150f45450e97a9812a9eaac915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65aa6394197e4ee18c4c23ded8d8713d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb07957144c14ef899cb42e19c9082c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c460a5008ed4503b1476e512f6146d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49e2ef477bb94d0c95a500b035f37fad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3723c3b7a7e341eea5b173145eb243dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f46c41f7a9a349cfb3b3b3b7f18fee92",
              "IPY_MODEL_77f5954bdea34dac98806e160a086cad",
              "IPY_MODEL_a4bc5d57a37442a183364968be2b4f0b"
            ],
            "layout": "IPY_MODEL_501a107674994d7794ac3d70393da4e4"
          }
        },
        "f46c41f7a9a349cfb3b3b3b7f18fee92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8dcec91701c4bacacb271db8b2efc7e",
            "placeholder": "​",
            "style": "IPY_MODEL_d8e7fcf53bc046e0bc65097501fb5cd5",
            "value": "Epoch 1:   9%"
          }
        },
        "77f5954bdea34dac98806e160a086cad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb83e8859bb040cbaf35cad2f9272ca0",
            "max": 16524,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ae22e3b85634edfa24be3200caa5143",
            "value": 1560
          }
        },
        "a4bc5d57a37442a183364968be2b4f0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b860dd7038db43588ac20056e8cab1f7",
            "placeholder": "​",
            "style": "IPY_MODEL_7c45dd7dac1d487f8e86cf46d1714020",
            "value": " 1560/16524 [06:08&lt;58:50,  4.24it/s, loss=0.00466, v_num=3]"
          }
        },
        "501a107674994d7794ac3d70393da4e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "e8dcec91701c4bacacb271db8b2efc7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8e7fcf53bc046e0bc65097501fb5cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb83e8859bb040cbaf35cad2f9272ca0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ae22e3b85634edfa24be3200caa5143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b860dd7038db43588ac20056e8cab1f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c45dd7dac1d487f8e86cf46d1714020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9fa2b653c9641a2b2068ea6eb13fe41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a67842602b843e2be7f83f0ae87019f",
              "IPY_MODEL_056d2a48b7054900b6cff5264aebfe75",
              "IPY_MODEL_f1d137c0169648efa6c77ccd73271447"
            ],
            "layout": "IPY_MODEL_ec66456ee1674eb994440c7a49869d96"
          }
        },
        "5a67842602b843e2be7f83f0ae87019f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99165b64fa74474faa0c3b437f869530",
            "placeholder": "​",
            "style": "IPY_MODEL_1c60e6b2bbbb4a859f3bc647bc878e8b",
            "value": "Validating: 100%"
          }
        },
        "056d2a48b7054900b6cff5264aebfe75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_459c4f79516c45b5b1d38342214fb5bb",
            "max": 2479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f52c9be7618e4ab7b93ecc7a3b5af181",
            "value": 2479
          }
        },
        "f1d137c0169648efa6c77ccd73271447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd60f126d8a24780994ee2327c242e9c",
            "placeholder": "​",
            "style": "IPY_MODEL_f79e364637ee4c6eaae92337003e8e91",
            "value": " 2479/2479 [03:45&lt;00:00, 11.25it/s]"
          }
        },
        "ec66456ee1674eb994440c7a49869d96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "99165b64fa74474faa0c3b437f869530": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c60e6b2bbbb4a859f3bc647bc878e8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "459c4f79516c45b5b1d38342214fb5bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f52c9be7618e4ab7b93ecc7a3b5af181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd60f126d8a24780994ee2327c242e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f79e364637ee4c6eaae92337003e8e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efb3f33635a54f28a9cd8947210f8f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e3375cfea194ad48a473f12c798fe1a",
              "IPY_MODEL_ebc75810ffc84f5cba8e6cd5598bdf11",
              "IPY_MODEL_7d42c685f35f4917ad28bf499bdb63d8"
            ],
            "layout": "IPY_MODEL_40b853bf5513414282bf5c9d599180d7"
          }
        },
        "9e3375cfea194ad48a473f12c798fe1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a454d47191ce4487aebdb4cb72512739",
            "placeholder": "​",
            "style": "IPY_MODEL_d81515bc787444d5a76367d3559ed8e3",
            "value": "Validation sanity check:   0%"
          }
        },
        "ebc75810ffc84f5cba8e6cd5598bdf11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78178524012a47dc84388bfb85c86949",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c963ed6f20e446a7a8589d583a6c91d3",
            "value": 0
          }
        },
        "7d42c685f35f4917ad28bf499bdb63d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34f6ae434fa144aa9cf73df5cd79b6fd",
            "placeholder": "​",
            "style": "IPY_MODEL_99fda0044e9d4beca7a1f0384866c5fa",
            "value": " 0/2 [00:00&lt;?, ?it/s]"
          }
        },
        "40b853bf5513414282bf5c9d599180d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "a454d47191ce4487aebdb4cb72512739": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d81515bc787444d5a76367d3559ed8e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78178524012a47dc84388bfb85c86949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c963ed6f20e446a7a8589d583a6c91d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34f6ae434fa144aa9cf73df5cd79b6fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99fda0044e9d4beca7a1f0384866c5fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "811a3d97990b4c70b0cc2daa9fd1673c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d07023965d049279dc85c53d769ff84",
              "IPY_MODEL_6b8f90d73d7941bb885da0697078fa5c",
              "IPY_MODEL_74e2981ebe8f4044ab1bd11fcd3a163e"
            ],
            "layout": "IPY_MODEL_19377f61581040ee82ee1c9958f94f43"
          }
        },
        "9d07023965d049279dc85c53d769ff84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8073ff25fa0842e783570c215bb20024",
            "placeholder": "​",
            "style": "IPY_MODEL_4a1ada1bf9154fe697e709f8382a940e",
            "value": "Epoch 0:   0%"
          }
        },
        "6b8f90d73d7941bb885da0697078fa5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a1f215b18bd4f558a961121618e25ca",
            "max": 16524,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5650909853124774beb69018d2c29c18",
            "value": 20
          }
        },
        "74e2981ebe8f4044ab1bd11fcd3a163e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c844c8692a040cb9cd87e834305677e",
            "placeholder": "​",
            "style": "IPY_MODEL_c2356fdb00674a5590bdb50c3d9e358a",
            "value": " 20/16524 [00:05&lt;1:15:23,  3.65it/s, loss=0.649, v_num=1]"
          }
        },
        "19377f61581040ee82ee1c9958f94f43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "8073ff25fa0842e783570c215bb20024": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a1ada1bf9154fe697e709f8382a940e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a1f215b18bd4f558a961121618e25ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5650909853124774beb69018d2c29c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c844c8692a040cb9cd87e834305677e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2356fdb00674a5590bdb50c3d9e358a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c8e1b931ddc49b894de4ab4162e38a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85fbe4274192478e9a79aa472a6b09a6",
              "IPY_MODEL_4116aabe3f564f468027605ff38364e6",
              "IPY_MODEL_64d58fbf0c25439e8dd7e9c6b7f9c290"
            ],
            "layout": "IPY_MODEL_2e119d682bef41a1875cf178a781906f"
          }
        },
        "85fbe4274192478e9a79aa472a6b09a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc7c121f658e4e10bec3f805524412f0",
            "placeholder": "​",
            "style": "IPY_MODEL_c99433c527c1413a852b5fbf1b8585bc",
            "value": "Testing: 100%"
          }
        },
        "4116aabe3f564f468027605ff38364e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bedd58b7248f40eb905924ad1ed46e63",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6438c367f8214d808af32e99f12678ef",
            "value": 1
          }
        },
        "64d58fbf0c25439e8dd7e9c6b7f9c290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56f1b30ef6fc45a396a4733a61bb2cb6",
            "placeholder": "​",
            "style": "IPY_MODEL_a0d0b4dfc1c9492dbb05aae46c4dc74f",
            "value": " 1954/1954 [02:03&lt;00:00, 16.05it/s]"
          }
        },
        "2e119d682bef41a1875cf178a781906f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "bc7c121f658e4e10bec3f805524412f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c99433c527c1413a852b5fbf1b8585bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bedd58b7248f40eb905924ad1ed46e63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6438c367f8214d808af32e99f12678ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56f1b30ef6fc45a396a4733a61bb2cb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0d0b4dfc1c9492dbb05aae46c4dc74f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZEbbNzy5H0j"
      },
      "source": [
        "# Science4Cast\n",
        "### A Machine Learning Challenge in the Science Of Science"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zvkXCeo5H0o"
      },
      "source": [
        "In this notebook you will learn the following:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfEk4XUZ5H0p"
      },
      "source": [
        "1. [How to read the data](#reading)\n",
        "2. [Visualizing the data](#visualizing)\n",
        "3. [Creating historic training data](#train)\n",
        "4. [Training a baseline model (incl. features, training)](#baseline)\n",
        "5. [Computing the metric: Area Under the Curve (AUC) ROC](#metric)\n",
        "6. [Evaluating Testset for Competition](#testset)\n",
        "7. [How to submit](#submit)\n",
        "\n",
        "### Mini-Summary\n",
        "In the competition you get\n",
        "- full_dynamic_graph_sparse: a dynamic graph (list of edges and their creation date) until a time t1.\n",
        "- unconnected_vertex_pairs: a list of 1,000,000 vertex pairs that are unconnected by time t1.\n",
        "\n",
        "**Your task in the competition** is to predict which edges of unconnected_vertex_pairs will form until a time t2. Specifically, you sort the list of potential edges in unconnected_vertex_pairs from most likely to most unlikely. The result will be computed via the [AUC of the ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEr7UguUuUYo"
      },
      "source": [
        "%%capture\n",
        "!pip install pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfPvBFFE5qC2",
        "outputId": "548906a1-2148-4b4d-e322-96319c7ad75a"
      },
      "source": [
        "%pip install -q stellargraph[demos]==1.2.1\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "DRIVE_PATH = \"/content/drive/My Drive/science4cast\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 21.6 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 22.2 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 92 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 245 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 256 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 266 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 276 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 286 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 296 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 307 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 317 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 327 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 337 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 348 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 358 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 368 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 378 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 389 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 399 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 409 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 419 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 430 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 435 kB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 407 kB 41.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.2 MB/s \n",
            "\u001b[?25h  Building wheel for mplleaflet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji_OypAWEjQV"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from math import isclose\n",
        "from scipy import sparse\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "from datetime import date\n",
        "from collections import Counter\n",
        "import multiprocessing\n",
        "from IPython.display import display, HTML\n",
        "from sklearn.model_selection import train_test_split\n",
        "import stellargraph as sg\n",
        "from stellargraph import StellarGraph, datasets\n",
        "from stellargraph.data import EdgeSplitter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa3X67qLuI80"
      },
      "source": [
        "# Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg2h2uqhlh4B"
      },
      "source": [
        "def create_training_data(full_graph,year_start,years_delta,edges_used=500000,vertex_degree_cutoff=10):\n",
        "    \"\"\"\n",
        "    :param full_graph: Full graph, numpy array dim(n,3) [vertex 1, vertex 2, time stamp]\n",
        "    :param year_start: year of graph\n",
        "    :param years_delta: distance for prediction in years (prediction on graph of year_start+years_delta)\n",
        "    :param edges_used: optional filter to create a random subset of edges for rapid prototyping (default: 500,000)\n",
        "    :param vertex_degree_cutoff: optional filter, for vertices in training set having a minimal degree of at least vertex_degree_cutoff  (default: 10)\n",
        "    :return:\n",
        "\n",
        "    all_edge_list: graph of year_start, numpy array dim(n,2)\n",
        "    unconnected_vertex_pairs: potential edges for year_start+years_delta\n",
        "    unconnected_vertex_pairs_solution: numpy array with integers (0=unconnected, 1=connected), solution, length = len(unconnected_vertex_pairs)\n",
        "    \"\"\"\n",
        "\n",
        "    years=[year_start,year_start+years_delta]    \n",
        "    print(years)\n",
        "    day_origin = date(1990,1,1)\n",
        "    \n",
        "    days_curr = (date(year_start,12,31)-day_origin).days\n",
        "    days_later = (date(year_start+years_delta,12,31)-day_origin).days\n",
        "\n",
        "    all_G = []\n",
        "\n",
        "    for days in [days_later, days_curr]:\n",
        "      all_edges=full_graph[full_graph[:,2]<=days]\n",
        "      print('    num of edges: ', len(all_edges))\n",
        "      adj_mat_sparse = sparse.csr_matrix((np.ones(len(all_edges)), (all_edges[:,0], all_edges[:,1])), shape=(NUM_OF_VERTICES,NUM_OF_VERTICES))\n",
        "      all_G.append(nx.from_scipy_sparse_matrix(adj_mat_sparse, parallel_edges=False, create_using=None, edge_attribute='weight'))\n",
        "\n",
        "    all_degs=np.array(adj_mat_sparse.sum(0))[0]\n",
        "\n",
        "    ## Create all edges to be predicted\n",
        "    all_vertices=np.array(range(NUM_OF_VERTICES))\n",
        "    vertex_large_degs=all_vertices[all_degs>=vertex_degree_cutoff] # use only vertices with degrees larger than 10.\n",
        "\n",
        "    ## get positive examples\n",
        "    all_edges_after = full_graph[(days_curr<full_graph[:,2]) & (full_graph[:,2]<=days_later)]\n",
        "    print(len(all_edges_after))\n",
        "    all_edges_after = all_edges_after[np.all(np.isin(all_edges_after[:,:2], vertex_large_degs), axis=1)]\n",
        "    print(len(all_edges_after))\n",
        "\n",
        "    ## get negative  examples\n",
        "    unconnected_vertex_pairs=[]\n",
        "\n",
        "    while len(unconnected_vertex_pairs) < max(edges_used, len(all_edges_after)):        \n",
        "        v1,v2=np.random.choice(vertex_large_degs, 2)\n",
        "\n",
        "        if (v1!=v2) and (not all_G[0].has_edge(v1,v2)) and (not all_G[1].has_edge(v1,v2)):\n",
        "            unconnected_vertex_pairs.append((v1,v2))\n",
        "\n",
        "    unconnected_vertex_pairs_solution=np.array([1]*len(all_edges_after)+[0]*len(unconnected_vertex_pairs))        \n",
        "    unconnected_vertex_pairs=np.vstack((all_edges_after[:, :2], np.array(unconnected_vertex_pairs)))\n",
        "  \n",
        "    print('Number of unconnected vertex pairs for prediction: ', len(unconnected_vertex_pairs_solution))\n",
        "    print('Number of vertex pairs that will be connected: ' , sum(unconnected_vertex_pairs_solution))\n",
        "    print('Ratio of vertex pairs that will be connected: ' , sum(unconnected_vertex_pairs_solution)/len(unconnected_vertex_pairs_solution))\n",
        "      \n",
        "    return np.array(all_edges), unconnected_vertex_pairs, unconnected_vertex_pairs_solution\n",
        "\n",
        "edges_used=1*10**6 # Best would be to use all vertices, to create more training data. But that takes long and requires huge amount of memory. So here we use a random subset.\n",
        "vertex_degree_cutoff=10\n",
        "\n",
        "def procrustes(X, Y, scaling=True, reflection='best'):\n",
        "    \"\"\"\n",
        "    A port of MATLAB's `procrustes` function to Numpy.\n",
        "\n",
        "    Procrustes analysis determines a linear transformation (translation,\n",
        "    reflection, orthogonal rotation and scaling) of the points in Y to best\n",
        "    conform them to the points in matrix X, using the sum of squared errors\n",
        "    as the goodness of fit criterion.\n",
        "\n",
        "        d, Z, [tform] = procrustes(X, Y)\n",
        "\n",
        "    Inputs:\n",
        "    ------------\n",
        "    X, Y    \n",
        "        matrices of target and input coordinates. they must have equal\n",
        "        numbers of  points (rows), but Y may have fewer dimensions\n",
        "        (columns) than X.\n",
        "\n",
        "    scaling \n",
        "        if False, the scaling component of the transformation is forced\n",
        "        to 1\n",
        "\n",
        "    reflection\n",
        "        if 'best' (default), the transformation solution may or may not\n",
        "        include a reflection component, depending on which fits the data\n",
        "        best. setting reflection to True or False forces a solution with\n",
        "        reflection or no reflection respectively.\n",
        "\n",
        "    Outputs\n",
        "    ------------\n",
        "    d       \n",
        "        the residual sum of squared errors, normalized according to a\n",
        "        measure of the scale of X, ((X - X.mean(0))**2).sum()\n",
        "\n",
        "    Z\n",
        "        the matrix of transformed Y-values\n",
        "\n",
        "    tform   \n",
        "        a dict specifying the rotation, translation and scaling that\n",
        "        maps X --> Y\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    n,m = X.shape\n",
        "    ny,my = Y.shape\n",
        "\n",
        "    muX = X.mean(0)\n",
        "    muY = Y.mean(0)\n",
        "\n",
        "    X0 = X - muX\n",
        "    Y0 = Y - muY\n",
        "\n",
        "    ssX = (X0**2.).sum()\n",
        "    ssY = (Y0**2.).sum()\n",
        "\n",
        "    # centred Frobenius norm\n",
        "    normX = np.sqrt(ssX)\n",
        "    normY = np.sqrt(ssY)\n",
        "\n",
        "    # scale to equal (unit) norm\n",
        "    X0 /= normX\n",
        "    Y0 /= normY\n",
        "\n",
        "    if my < m:\n",
        "        Y0 = np.concatenate((Y0, np.zeros(n, m-my)),0)\n",
        "\n",
        "    # optimum rotation matrix of Y\n",
        "    A = np.dot(X0.T, Y0)\n",
        "    U,s,Vt = np.linalg.svd(A,full_matrices=False)\n",
        "    V = Vt.T\n",
        "    T = np.dot(V, U.T)\n",
        "\n",
        "    if reflection != 'best':\n",
        "\n",
        "        # does the current solution use a reflection?\n",
        "        have_reflection = np.linalg.det(T) < 0\n",
        "\n",
        "        # if that's not what was specified, force another reflection\n",
        "        if reflection != have_reflection:\n",
        "            V[:,-1] *= -1\n",
        "            s[-1] *= -1\n",
        "            T = np.dot(V, U.T)\n",
        "\n",
        "    traceTA = s.sum()\n",
        "\n",
        "    if scaling:\n",
        "\n",
        "        # optimum scaling of Y\n",
        "        b = traceTA * normX / normY\n",
        "\n",
        "        # standarised distance between X and b*Y*T + c\n",
        "        d = 1 - traceTA**2\n",
        "\n",
        "        # transformed coords\n",
        "        Z = normX*traceTA*np.dot(Y0, T) + muX\n",
        "\n",
        "    else:\n",
        "        b = 1\n",
        "        d = 1 + ssY/ssX - 2 * traceTA * normY / normX\n",
        "        Z = normY*np.dot(Y0, T) + muX\n",
        "\n",
        "    # transformation matrix\n",
        "    if my < m:\n",
        "        T = T[:my,:]\n",
        "    c = muX - b*np.dot(muY, T)\n",
        "    \n",
        "    #transformation values \n",
        "    tform = {'rotation':T, 'scale':b, 'translation':c}\n",
        "   \n",
        "    return d, Z, tform\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# 1. link embeddings\n",
        "def link_examples_to_features(link_examples, embedding, binary_operator):\n",
        "    return binary_operator(embedding[link_examples[:,0]], embedding[link_examples[:,1]])\n",
        "\n",
        "# 2. training classifier\n",
        "def train_link_prediction_model(link_examples, link_labels, get_embedding, binary_operator):\n",
        "    clf = link_prediction_classifier()\n",
        "    link_features = link_examples_to_features(\n",
        "        link_examples, get_embedding, binary_operator\n",
        "    )\n",
        "    clf.fit(link_features, link_labels)\n",
        "    return clf\n",
        "\n",
        "\n",
        "def link_prediction_classifier(max_iter=5000):\n",
        "    lr_clf = LogisticRegressionCV(Cs=10, cv=5, scoring=\"roc_auc\", max_iter=max_iter)\n",
        "    return Pipeline(steps=[(\"sc\", StandardScaler()), (\"clf\", lr_clf)])\n",
        "\n",
        "\n",
        "# 3. and 4. evaluate classifier\n",
        "def evaluate_link_prediction_model(clf, link_examples_test, link_labels_test, get_embedding, binary_operator):\n",
        "    link_features_test = link_examples_to_features(\n",
        "        link_examples_test, get_embedding, binary_operator\n",
        "    )\n",
        "    score = evaluate_roc_auc(clf, link_features_test, link_labels_test)\n",
        "    return score\n",
        "\n",
        "\n",
        "def evaluate_roc_auc(clf, link_features, link_labels):\n",
        "    predicted = clf.predict_proba(link_features)\n",
        "\n",
        "    # check which class corresponds to positive links\n",
        "    positive_column = list(clf.classes_).index(1)\n",
        "    return roc_auc_score(link_labels, predicted[:, positive_column])\n",
        "\n",
        "def operator_hadamard(u, v):\n",
        "    return u * v\n",
        "\n",
        "\n",
        "def operator_l1(u, v):\n",
        "    return np.abs(u - v)\n",
        "\n",
        "\n",
        "def operator_l2(u, v):\n",
        "    return (u - v) ** 2\n",
        "\n",
        "\n",
        "def operator_avg(u, v):\n",
        "    return (u + v) / 2.0\n",
        "\n",
        "def operator_concat(u,v):\n",
        "    return np.hstack((u,v))\n",
        "\n",
        "\n",
        "def run_link_prediction(binary_operator, embedding_train):\n",
        "    clf = train_link_prediction_model(\n",
        "        examples_train, labels_train, embedding_train, binary_operator\n",
        "    )\n",
        "    score = evaluate_link_prediction_model(\n",
        "        clf,\n",
        "        examples_model_selection,\n",
        "        labels_model_selection,\n",
        "        embedding_train,\n",
        "        binary_operator,\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"classifier\": clf,\n",
        "        \"binary_operator\": binary_operator,\n",
        "        \"score\": score,\n",
        "        \"embedding\": embedding_train,\n",
        "    }\n",
        "\n",
        "#binary_operators = [operator_hadamard, operator_l1, operator_l2, operator_avg]\n",
        "binary_operators = [operator_l2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsZ3Ffwp5H0q"
      },
      "source": [
        "<a id='reading'></a>\n",
        "# 1. How to read the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALF0x7Gj5H0r"
      },
      "source": [
        "First, get the data from the [IARAI cloud](https://cloud.iarai.ac.at/index.php/s/iTx3bXgMdwsngPn). It contains three files:\n",
        "- **TrainSet2014_3.pkl:** (33 MB) Semantic network until 2014, and list of unconnected vertex-pairs that can be predicted for training the neural network.\n",
        "- **TrainSet2014_3_solution.pkl**: (0.5 MB) Solution of whether the unconnected vertex pair from 2014 has been connected by 2017.\n",
        "- **CompetitionSet2017_3.pkl**: (95 MB) Semantic network until 2017, and list of unconnected vertex-pairs that should be predicted for the evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtDcYPdI5H0r"
      },
      "source": [
        "Afterwards we can read *TrainSet2014_3.pkl* using pickle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MnuTJZ05H0s",
        "scrolled": true,
        "outputId": "9d861c7b-bf76-4b68-f466-a14ca7d8dcd6"
      },
      "source": [
        "NUM_OF_VERTICES=64719 # number of vertices of the semantic net\n",
        "DRIVE_PATH = \"/content/drive/My Drive/science4cast\"\n",
        "data_source = os.path.join(DRIVE_PATH, 'competition_data/CompetitionSet2017_3.pkl')\n",
        "#data_source = os.path.join(DRIVE_PATH, 'TrainSet2014_3.pkl')\n",
        "full_dynamic_graph_sparse,unconnected_vertex_pairs,year_start,years_delta = pickle.load( open( data_source, \"rb\" ) )\n",
        "\n",
        "print(data_source+' has '+str(len(full_dynamic_graph_sparse))+' edges between a total of '+str(NUM_OF_VERTICES)+ ' vertices.\\n\\n')\n",
        "print('The goal is to predict which of '+str(len(unconnected_vertex_pairs))+' unconnectedvertex-pairs\\nin unconnected_vertex_pairs will be connected until '+str(year_start+years_delta)+'.')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/science4cast/competition_data/CompetitionSet2017_3.pkl has 7652945 edges between a total of 64719 vertices.\n",
            "\n",
            "\n",
            "The goal is to predict which of 1000000 unconnectedvertex-pairs\n",
            "in unconnected_vertex_pairs will be connected until 2020.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtlbRU6Xorug",
        "outputId": "c92705c0-a65d-4e8d-e647-59340f488ba7"
      },
      "source": [
        "print(year_start)\n",
        "year_start = 1994"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHCKRoYT5H0u"
      },
      "source": [
        " - **full_dynamic_graph_sparse:** The entire semantic network until 2014 or 2017. It is a numpy array, each entry describes an edge in the semantic network. Each edge is described by three numbers [v1, v2, t], where the edge is formed at time t between vertices v1 and v2. t is measured in days since the 1.1.1990.\n",
        "\n",
        "- **unconnected_vertex_pairs:** This is a list of vertex pairs v1,v2 with deg(v1)>=10, deg(v2)>=10, and no edge exists in the year 2014. The question that the neural network needs to solve: Will an edge form? It does not contain all unconnected vertices, but a random subset.\n",
        "\n",
        "\n",
        "- **year_start:** year_start=2014\n",
        "\n",
        "\n",
        "- **years_delta:** years_delta=3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEixFf435H0w"
      },
      "source": [
        "The first and second number stand are indices of a vertex, the 3rd number stands for a time stamp (in days since 1.1.1990). \n",
        "\n",
        "For example, the first entry, edge #466956 between vertex 35266 and 36996 has been formed 7758 days after the 1.1.1990. Each of the 64719 vertices stand for a concept in AI or machine learning (its meanings are not revealed during the competition). An edge is formed between the concepts when they co-appear in a scientific paper (specifically, in its title or abstracts).\n",
        "\n",
        "Next let's see *unconnected_vertex_pairs*:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRuXEztJ5H0x"
      },
      "source": [
        "The two indices stand for two vertices. Those two vertices have both a degree larger than 10, but are not connected. The question is whether these concept pairs, for instance (79, 184), will be connected 3 years later. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArHX56Va5H00"
      },
      "source": [
        "<a id='train'></a>\n",
        "## 3. Creating historic training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uERwRjNS5H01"
      },
      "source": [
        "Next, we create training data for the baseline model. The baseline model uses historic states of the neural network, to predict whether unconnected vertices will be connected.\n",
        "\n",
        "For the validation run, we use the semantic net from 2014 to predict 2017. Therefore, we create training data from 2011 -> 2014. After the training we then can predict 2017."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW6b1Yeu5H01",
        "scrolled": true
      },
      "source": [
        "def create_training_data(full_graph,year_start,years_delta,edges_used=500000,vertex_degree_cutoff=10):\n",
        "    \"\"\"\n",
        "    :param full_graph: Full graph, numpy array dim(n,3) [vertex 1, vertex 2, time stamp]\n",
        "    :param year_start: year of graph\n",
        "    :param years_delta: distance for prediction in years (prediction on graph of year_start+years_delta)\n",
        "    :param edges_used: optional filter to create a random subset of edges for rapid prototyping (default: 500,000)\n",
        "    :param vertex_degree_cutoff: optional filter, for vertices in training set having a minimal degree of at least vertex_degree_cutoff  (default: 10)\n",
        "    :return:\n",
        "\n",
        "    all_edge_list: graph of year_start, numpy array dim(n,2)\n",
        "    unconnected_vertex_pairs: potential edges for year_start+years_delta\n",
        "    unconnected_vertex_pairs_solution: numpy array with integers (0=unconnected, 1=connected), solution, length = len(unconnected_vertex_pairs)\n",
        "    \"\"\"\n",
        "\n",
        "    years=[year_start,year_start+years_delta]    \n",
        "    day_origin = date(1990,1,1)\n",
        "\n",
        "    all_G=[]\n",
        "    all_edge_lists=[]\n",
        "    all_sparse=[]\n",
        "    for yy in years:\n",
        "        print('    Create Graph for ', yy)\n",
        "        day_curr=date(yy,12,31)\n",
        "        all_edges_curr=full_graph[full_graph[:,2]<(day_curr-day_origin).days]\n",
        "        adj_mat_sparse_curr = sparse.csr_matrix((np.ones(len(all_edges_curr)), (all_edges_curr[:,0], all_edges_curr[:,1])), shape=(NUM_OF_VERTICES,NUM_OF_VERTICES))\n",
        "        G_curr=nx.from_scipy_sparse_matrix(adj_mat_sparse_curr, parallel_edges=False, create_using=None, edge_attribute='weight')\n",
        "\n",
        "        all_G.append(G_curr)\n",
        "        all_sparse.append(adj_mat_sparse_curr)\n",
        "        all_edge_lists.append(all_edges_curr)\n",
        "\n",
        "        print('    Done: Create Graph for ', yy)\n",
        "        print('    num of edges: ', G_curr.number_of_edges())\n",
        "\n",
        "    all_degs=np.array(all_sparse[0].sum(0))[0]\n",
        "\n",
        "    ## Create all edges to be predicted\n",
        "    all_vertices=np.array(range(NUM_OF_VERTICES))\n",
        "    vertex_large_degs=all_vertices[all_degs>=vertex_degree_cutoff] # use only vertices with degrees larger than 10.\n",
        "\n",
        "    unconnected_vertex_pairs=[]\n",
        "    unconnected_vertex_pairs_solution=[]\n",
        "\n",
        "    time_start=time.time()\n",
        "    while len(unconnected_vertex_pairs)<edges_used:        \n",
        "        v1,v2=random.sample(range(len(vertex_large_degs)), 2)\n",
        "\n",
        "        if v1!=v2 and not all_G[0].has_edge(v1,v2):\n",
        "            if len(unconnected_vertex_pairs)%10**6==0:\n",
        "                time_end=time.time()\n",
        "                print('    edge progress (',time_end-time_start,'sec): ',len(unconnected_vertex_pairs)/10**6,'M/',edges_used/10**6,'M')\n",
        "                time_start=time.time()\n",
        "            unconnected_vertex_pairs.append((v1,v2))\n",
        "            unconnected_vertex_pairs_solution.append(all_G[1].has_edge(v1,v2))\n",
        "\n",
        "        \n",
        "    print('Number of unconnected vertex pairs for prediction: ', len(unconnected_vertex_pairs_solution))\n",
        "    print('Number of vertex pairs that will be connected: ' , sum(unconnected_vertex_pairs_solution))\n",
        "    print('Ratio of vertex pairs that will be connected: ' , sum(unconnected_vertex_pairs_solution)/len(unconnected_vertex_pairs_solution))\n",
        "    \n",
        "    unconnected_vertex_pairs=np.array(unconnected_vertex_pairs)\n",
        "    unconnected_vertex_pairs_solution=np.array(list(map(int, unconnected_vertex_pairs_solution)))\n",
        "    all_edge_list=np.array(all_edge_lists[0])\n",
        "    \n",
        "    return all_edge_list, unconnected_vertex_pairs, unconnected_vertex_pairs_solution\n",
        "\n",
        "edges_used=1*10**6 # Best would be to use all vertices, to create more training data. But that takes long and requires huge amount of memory. So here we use a random subset.\n",
        "vertex_degree_cutoff=10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yav6-MDgIMRr",
        "outputId": "450de55f-db8b-419f-ddf6-8772a16af234"
      },
      "source": [
        "train_dynamic_graph_sparse,train_edges_for_checking,train_edges_solution = create_training_data(full_dynamic_graph_sparse, year_start, years_delta, edges_used=edges_used, vertex_degree_cutoff=vertex_degree_cutoff)\n",
        "\n",
        "print(train_dynamic_graph_sparse[:,:-1].shape, train_edges_for_checking.shape, train_edges_solution.shape)\n",
        "graph_train = StellarGraph(nodes=sg.IndexedArray(index=range(NUM_OF_VERTICES)), \n",
        "                          edges=pd.DataFrame(train_dynamic_graph_sparse[:,:-1], columns=[\"source\", \"target\"]))\n",
        "print(graph_train.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Create Graph for  1994\n",
            "    Done: Create Graph for  1994\n",
            "    num of edges:  671\n",
            "    Create Graph for  1997\n",
            "    Done: Create Graph for  1997\n",
            "    num of edges:  6749\n",
            "    edge progress ( 0.00011849403381347656 sec):  0.0 M/ 1.0 M\n",
            "Number of unconnected vertex pairs for prediction:  1000000\n",
            "Number of vertex pairs that will be connected:  0\n",
            "Ratio of vertex pairs that will be connected:  0.0\n",
            "(671, 2) (1000000, 2) (1000000,)\n",
            "StellarGraph: Undirected multigraph\n",
            " Nodes: 64719, Edges: 671\n",
            "\n",
            " Node types:\n",
            "  default: [64719]\n",
            "    Features: none\n",
            "    Edge types: default-default->default\n",
            "\n",
            " Edge types:\n",
            "    default-default->default: [671]\n",
            "        Weights: all 1 (default)\n",
            "        Features: none\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5z103PBDeg6"
      },
      "source": [
        "## Node Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CtIK-EymrRu"
      },
      "source": [
        "This demo notebook compares the link prediction performance of the embeddings learned by Node2Vec [1], Attri2Vec [2], GraphSAGE [3] and GCN [4] on the Cora dataset, under the same edge train-test-split setting. Node2Vec and Attri2Vec are learned by capturing the random walk context node similarity. GraphSAGE and GCN are learned in an unsupervised way by making nodes co-occurring in short random walks represented closely in the embedding space.\n",
        "\n",
        "We're going to tackle link prediction as a supervised learning problem on top of node representations/embeddings. After obtaining embeddings, a binary classifier can be used to predict a link, or not, between any two nodes in the graph. Various hyperparameters could be relevant in obtaining the best link classifier - this demo demonstrates incorporating model selection into the pipeline for choosing the best binary operator to apply on a pair of node embeddings.\n",
        "\n",
        "There are four steps:\n",
        "\n",
        "1. Obtain embeddings for each node\n",
        "2. For each set of hyperparameters, train a classifier\n",
        "3. Select the classifier that performs the best\n",
        "4. Evaluate the selected classifier on unseen data to validate its ability to generalise\n",
        "\n",
        "\n",
        "**References:** \n",
        "\n",
        "[1] Node2Vec: Scalable Feature Learning for Networks. A. Grover, J. Leskovec. ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), 2016.\n",
        "\n",
        "[2] Attributed Network Embedding via Subspace Discovery. D. Zhang, Y. Jie, X. Zhu and C. Zhang. Data Mining and Knowledge Discovery, 2019. \n",
        "\n",
        "[3] Inductive Representation Learning on Large Graphs. W.L. Hamilton, R. Ying, and J. Leskovec. Neural Information Processing Systems (NIPS), 2017.\n",
        "\n",
        "[4] Graph Convolutional Networks (GCN): Semi-Supervised Classification with Graph Convolutional Networks. Thomas N. Kipf, Max Welling. International Conference on Learning Representations (ICLR), 2017"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkf27-Wrlizj"
      },
      "source": [
        "We define the helper function to generate biased random walks from the given graph with the fixed random walk parameters:\n",
        "\n",
        "* `p` - Random walk parameter \"p\" that defines probability, \"1/p\", of returning to source node\n",
        "* `q` - Random walk parameter \"q\" that defines probability, \"1/q\", for moving to a node away from the source node"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xNaXXY_DtPu"
      },
      "source": [
        "from stellargraph.data import BiasedRandomWalk\n",
        "\n",
        "\n",
        "def create_biased_random_walker(graph, walk_num, walk_length):\n",
        "    # parameter settings for \"p\" and \"q\":\n",
        "    p = 2.0\n",
        "    q = 1.0\n",
        "    return BiasedRandomWalk(graph, n=walk_num, length=walk_length, p=p, q=q)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xUN7pSslmPu"
      },
      "source": [
        "We train Node2Vec, Attri2Vec, GraphSAGE, and GCN by following the same unsupervised learning procedure: we firstly generate a set of short random walks from the given graph and then learn node embeddings from batches of `target, context` pairs collected from random walks. For learning node embeddings, we need to specify the following parameters:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuOH37bLlmVr"
      },
      "source": [
        "* `dimension` - Dimensionality of node embeddings\n",
        "* `walk_number` - Number of walks from each node\n",
        "* `walk_length` - Length of each random walk\n",
        "* `epochs` - The number of epochs to train embedding learning model\n",
        "* `batch_size` - The batch size to train embedding learning model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1EdelSHlrbf"
      },
      "source": [
        "We consistently set the node embedding dimension to 128 for all algorithms. However, we use different hidden layers to learn node embeddings for different algorithms to exert their respective power. For the remaining parameters, we set them as:\n",
        "\n",
        "|               | Node2Vec | Attri2Vec | GraphSAGE | GCN |\n",
        "|---------------|----------|-----------|-----------|-----|\n",
        "| `walk_number` |    20    |     4     |     1     |  1  |\n",
        "| `walk_length` |     5    |     5     |     5     |  5  |\n",
        "| `epochs`      |    6     |     6     |     6     |  6  |\n",
        "| `batch_size`  |    50    |     50    |    50     |  50 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81iReUcDlvzv"
      },
      "source": [
        "As all algorithms use the same `walk_length`, `batch_size` and `epochs` values, we uniformly set them here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuS8GxW5D30I"
      },
      "source": [
        "walk_length = 5\n",
        "epochs = 100\n",
        "batch_size = 512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL5SJDPujVT0"
      },
      "source": [
        "### Node2Vec\n",
        "\n",
        "We use Node2Vec [1], to calculate node embeddings. These embeddings are learned in such a way to ensure that nodes that are close in the graph remain close in the embedding space. We train Node2Vec with the Stellargraph Node2Vec components."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-mPxpliEBiK"
      },
      "source": [
        "from stellargraph.data import UnsupervisedSampler\n",
        "from stellargraph.mapper import Node2VecLinkGenerator, Node2VecNodeGenerator\n",
        "from stellargraph.layer import Node2Vec, link_classification\n",
        "from tensorflow import keras\n",
        "\n",
        "def node2vec_embedding(graph, name):\n",
        "\n",
        "    # Set the embedding dimension and walk number:\n",
        "    dimension = 128\n",
        "    walk_number = 20\n",
        "\n",
        "    print(f\"Training Node2Vec for '{name}':\")\n",
        "\n",
        "    graph_node_list = list(graph.nodes())\n",
        "\n",
        "    # Create the biased random walker to generate random walks\n",
        "    walker = create_biased_random_walker(graph, walk_number, walk_length)\n",
        "\n",
        "    # Create the unsupervised sampler to sample (target, context) pairs from random walks\n",
        "    unsupervised_samples = UnsupervisedSampler(\n",
        "        graph, nodes=graph_node_list, walker=walker\n",
        "    )\n",
        "\n",
        "    # Define a Node2Vec training generator, which generates batches of training pairs\n",
        "    generator = Node2VecLinkGenerator(graph, batch_size)\n",
        "\n",
        "    # Create the Node2Vec model\n",
        "    node2vec = Node2Vec(dimension, generator=generator)\n",
        "\n",
        "    # Build the model and expose input and output sockets of Node2Vec, for node pair inputs\n",
        "    x_inp, x_out = node2vec.in_out_tensors()\n",
        "\n",
        "    # Use the link_classification function to generate the output of the Node2Vec model\n",
        "    prediction = link_classification(\n",
        "        output_dim=1, output_act=\"sigmoid\", edge_embedding_method=\"dot\"\n",
        "    )(x_out)\n",
        "\n",
        "    # Stack the Node2Vec encoder and prediction layer into a Keras model, and specify the loss\n",
        "    model = keras.Model(inputs=x_inp, outputs=prediction)\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss=keras.losses.binary_crossentropy,\n",
        "        metrics=[keras.metrics.binary_accuracy],\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        generator.flow(unsupervised_samples),\n",
        "        epochs=epochs,\n",
        "        verbose=2,\n",
        "        callbacks = [keras.callbacks.EarlyStopping(monitor='loss', patience=2, restore_best_weights=True),\n",
        "                     keras.callbacks.ModelCheckpoint(filepath=os.path.join(DRIVE_PATH,'node2vec'+str(date.today())+'.h5'),\n",
        "                                                     monitor='loss',save_best_only=True),\n",
        "                    keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
        "                              patience=1, min_lr=1e-4)],\n",
        "        use_multiprocessing=True,\n",
        "        workers=8,\n",
        "    )\n",
        "\n",
        "    # Build the model to predict node representations from node ids with the learned Node2Vec model parameters\n",
        "    x_inp_src = x_inp[0]\n",
        "    x_out_src = x_out[0]\n",
        "    embedding_model = keras.Model(inputs=x_inp_src, outputs=x_out_src)\n",
        "\n",
        "    # Get representations for all nodes in ``graph``\n",
        "    node_gen = Node2VecNodeGenerator(graph, batch_size).flow(graph_node_list)\n",
        "    node_embeddings = embedding_model.predict(node_gen, workers=8, verbose=2, use_multiprocessing=True)\n",
        "    \n",
        "    with open(os.path.join(DRIVE_PATH, 'node2vec-'+str(year_start)+'.pkl'), \"wb\") as output_file:\n",
        "        pickle.dump(node_embeddings, output_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    return node_embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC8GdM4UjpAw"
      },
      "source": [
        "from stellargraph.mapper import FullBatchLinkGenerator, FullBatchNodeGenerator\n",
        "from stellargraph.layer import GCN, LinkEmbedding\n",
        "\n",
        "\n",
        "def gcn_embedding(graph, name):\n",
        "\n",
        "    # Set the embedding dimensions and walk number:\n",
        "    dimensions = [128, 128]\n",
        "    walk_number = 1\n",
        "\n",
        "    print(f\"Training GCN for '{name}':\")\n",
        "\n",
        "    graph_node_list = list(graph.nodes())\n",
        "\n",
        "    # Create the biased random walker to generate random walks\n",
        "    walker = create_biased_random_walker(graph, walk_number, walk_length)\n",
        "\n",
        "    # Create the unsupervised sampler to sample (target, context) pairs from random walks\n",
        "    unsupervised_samples = UnsupervisedSampler(\n",
        "        graph, nodes=graph_node_list, walker=walker\n",
        "    )\n",
        "\n",
        "    # Define a GCN training generator, which generates the full batch of training pairs\n",
        "    generator = FullBatchLinkGenerator(graph, method=\"gcn\")\n",
        "\n",
        "    # Create the GCN model\n",
        "    gcn = GCN(\n",
        "        layer_sizes=dimensions,\n",
        "        activations=[\"relu\", \"relu\"],\n",
        "        generator=generator,\n",
        "        dropout=0.3,\n",
        "    )\n",
        "\n",
        "    # Build the model and expose input and output sockets of GCN, for node pair inputs\n",
        "    x_inp, x_out = gcn.in_out_tensors()\n",
        "\n",
        "    # Use the dot product of node embeddings to make node pairs co-occurring in short random walks represented closely\n",
        "    prediction = LinkEmbedding(activation=\"sigmoid\", method=\"ip\")(x_out)\n",
        "    prediction = keras.layers.Reshape((-1,))(prediction)\n",
        "\n",
        "    # Stack the GCN encoder and prediction layer into a Keras model, and specify the loss\n",
        "    model = keras.Model(inputs=x_inp, outputs=prediction)\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(lr=1e-3),\n",
        "        loss=keras.losses.binary_crossentropy,\n",
        "        metrics=[keras.metrics.binary_accuracy],\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    batches = unsupervised_samples.run(batch_size)\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch: {epoch+1}/{epochs}\")\n",
        "        batch_iter = 1\n",
        "        for batch in batches:\n",
        "            samples = generator.flow(batch[0], targets=batch[1], use_ilocs=True)[0]\n",
        "            [loss, accuracy] = model.train_on_batch(x=samples[0], y=samples[1])\n",
        "            output = (\n",
        "                f\"{batch_iter}/{len(batches)} - loss:\"\n",
        "                + \" {:6.4f}\".format(loss)\n",
        "                + \" - binary_accuracy:\"\n",
        "                + \" {:6.4f}\".format(accuracy)\n",
        "            )\n",
        "            if batch_iter == len(batches):\n",
        "                print(output)\n",
        "            else:\n",
        "                print(output, end=\"\\r\")\n",
        "            batch_iter = batch_iter + 1\n",
        "\n",
        "    # Get representations for all nodes in ``graph``\n",
        "    embedding_model = keras.Model(inputs=x_inp, outputs=x_out)\n",
        "    node_embeddings = embedding_model.predict(\n",
        "        generator.flow(list(zip(graph_node_list, graph_node_list)))\n",
        "    )\n",
        "    node_embeddings = node_embeddings[0][:, 0, :]\n",
        "\n",
        "    def get_embedding(u):\n",
        "        u_index = graph_node_list.index(u)\n",
        "        return node_embeddings[u_index]\n",
        "\n",
        "    return get_embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "4RJqlTn5Fw1a",
        "outputId": "30ba4ce9-8357-44e7-bfce-0984e2332ece"
      },
      "source": [
        "node_embeddings = node2vec_embedding(graph_train, \"Node2Vec\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Node2Vec for 'Node2Vec':\n",
            "link_classification: using 'dot' method to combine node embeddings into edge embeddings\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-583f15c3560c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnode_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode2vec_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Node2Vec\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-def8f4244040>\u001b[0m in \u001b[0;36mnode2vec_embedding\u001b[0;34m(graph, name)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     model.fit(\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munsupervised_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stellargraph/mapper/sampled_link_generators.py\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, link_ids, targets, shuffle, seed)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# Pass sampler to on-demand link sequence generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnsupervisedSampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mOnDemandLinkSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlink_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# Otherwise pass iterable (check?) to standard LinkSequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stellargraph/mapper/sequences.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sample_function, batch_size, walker, shuffle)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;31m# FIXME(#681): all batches are created at once, so this is no longer \"on demand\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stellargraph/mapper/sequences.py\u001b[0m in \u001b[0;36m_create_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_create_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stellargraph/data/unsupervised_sampler.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    152\u001b[0m         )\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mwalks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m# first item in each walk is the target/head node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/stellargraph/data/explorer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, nodes, n, length, p, q, seed, weighted)\u001b[0m\n\u001b[1;32m    492\u001b[0m                             \u001b[0mcurrent_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_ilocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m                         )\n\u001b[0;32m--> 494\u001b[0;31m                         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbours\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbours\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mones\u001b[0;34m(shape, dtype, order)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \"\"\"\n\u001b[1;32m    192\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mmultiarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'unsafe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcopyto\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "judLDfkuTebt"
      },
      "source": [
        "year_start = 2009\n",
        "train_dynamic_graph_sparse,train_edges_for_checking,train_edges_solution = create_training_data(full_dynamic_graph_sparse, year_start, years_delta, edges_used=edges_used, vertex_degree_cutoff=vertex_degree_cutoff)\n",
        "\n",
        "print(train_dynamic_graph_sparse[:,:-1].shape, train_edges_for_checking.shape, train_edges_solution.shape)\n",
        "graph_train = StellarGraph(nodes=sg.IndexedArray(index=range(NUM_OF_VERTICES)), \n",
        "                          edges=pd.DataFrame(train_dynamic_graph_sparse[:,:-1], columns=[\"source\", \"target\"]))\n",
        "print(graph_train.info())\n",
        "node_embeddings = node2vec_embedding(graph_train, \"Node2Vec\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3CmnFCITfZ8"
      },
      "source": [
        "year_start = 2010\n",
        "train_dynamic_graph_sparse,train_edges_for_checking,train_edges_solution = create_training_data(full_dynamic_graph_sparse, year_start, years_delta, edges_used=edges_used, vertex_degree_cutoff=vertex_degree_cutoff)\n",
        "\n",
        "print(train_dynamic_graph_sparse[:,:-1].shape, train_edges_for_checking.shape, train_edges_solution.shape)\n",
        "graph_train = StellarGraph(nodes=sg.IndexedArray(index=range(NUM_OF_VERTICES)), \n",
        "                          edges=pd.DataFrame(train_dynamic_graph_sparse[:,:-1], columns=[\"source\", \"target\"]))\n",
        "print(graph_train.info())\n",
        "node_embeddings = node2vec_embedding(graph_train, \"Node2Vec\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFqUDEF9hUBd"
      },
      "source": [
        "# Procrustes Alignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSiugHA9hV-e"
      },
      "source": [
        "# Read the data\n",
        "\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/science4cast/node2vec_embeddings/\"\n",
        "with open(os.path.join(DRIVE_PATH, 'node2vec-2015.pkl'), \"rb\") as output_file:\n",
        "    embedding_2015 = pickle.load(output_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opcGECByhpB8"
      },
      "source": [
        "embeddings = []\n",
        "year_start = 2004\n",
        "num_years = 14\n",
        "for i in range(num_years):\n",
        "  year = i+year_start\n",
        "  name = 'node2vec-'+str(year) +'.pkl'\n",
        "  with open(\"/content/drive/MyDrive/science4cast/node2vec_embeddings/\"+name, \"rb\") as pickle_file:\n",
        "    embeddings = embeddings + [pickle.load(pickle_file)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egq_ngCpijq6"
      },
      "source": [
        "aligned_embeddings = []\n",
        "num_years = 14\n",
        "for i in range(num_years):\n",
        "  d,Z,tform = procrustes(embeddings[-1], embeddings[i])\n",
        "  aligned_embeddings = aligned_embeddings + [Z]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ACCyrU2kS9p"
      },
      "source": [
        "with open(os.path.join(DRIVE_PATH, \"aligned_to_2017_embeddings.pkl\"), \"wb\") as output_file:\n",
        "        pickle.dump(aligned_embeddings, output_file, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcwgcJ-Ikg9U"
      },
      "source": [
        "num_nodes,embed_dim = aligned_embeddings[0].shape\n",
        "data = torch.zeros(num_years, num_nodes, embed_dim) #torch.tensor(aligned_embeddings[0])\n",
        "for i in range(num_years):\n",
        "  data[i,:,:] = torch.tensor(aligned_embeddings[i]) #torch.cat((data,torch.tensor(aligned_embeddings[i])), dim = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewyhY79uT_e9"
      },
      "source": [
        "embeddings = 0\n",
        "aligned_embeddings = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUtUDHxnkjCU",
        "outputId": "4128340a-3ff6-43ea-d037-71f7e247628c"
      },
      "source": [
        "print(data.shape)\n",
        "M = data.shape[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([23, 64719, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIKEfQaVklSO"
      },
      "source": [
        "model = torch.nn.Sequential(nn.Linear(2*M,M), \n",
        "                            nn.ReLU(),\n",
        "                            nn.Linear(M,M),\n",
        "                            nn.ReLU(), \n",
        "                            nn.Linear(M,M), \n",
        "                            nn.ReLU(),\n",
        "                            nn.Linear(M,M),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Linear(M,2))\n",
        "model = model.to('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj3XSDZ_k5zK",
        "outputId": "461b1cf8-b1dc-46c2-e2e7-64c4fcd1595d"
      },
      "source": [
        "train_dynamic_graph_sparse,train_edges_for_checking,train_edges_solution = create_training_data(full_dynamic_graph_sparse, 2016, 1, edges_used=edges_used, vertex_degree_cutoff=vertex_degree_cutoff)\n",
        "\n",
        "print(train_dynamic_graph_sparse[:,:-1].shape, train_edges_for_checking.shape, train_edges_solution.shape)\n",
        "graph_train = StellarGraph(nodes=sg.IndexedArray(index=range(NUM_OF_VERTICES)), \n",
        "                          edges=pd.DataFrame(train_dynamic_graph_sparse[:,:-1], columns=[\"source\", \"target\"]))\n",
        "print(graph_train.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2016, 2017]\n",
            "    num of edges:  7652945\n",
            "    num of edges:  5019764\n",
            "2633181\n",
            "2114881\n",
            "Number of unconnected vertex pairs for prediction:  4229762\n",
            "Number of vertex pairs that will be connected:  2114881\n",
            "Ratio of vertex pairs that will be connected:  0.5\n",
            "(5019764, 2) (4229762, 2) (4229762,)\n",
            "StellarGraph: Undirected multigraph\n",
            " Nodes: 64719, Edges: 5019764\n",
            "\n",
            " Node types:\n",
            "  default: [64719]\n",
            "    Features: none\n",
            "    Edge types: default-default->default\n",
            "\n",
            " Edge types:\n",
            "    default-default->default: [5019764]\n",
            "        Weights: all 1 (default)\n",
            "        Features: none\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiu7x7uTlgKf"
      },
      "source": [
        "(   examples_train,\n",
        "    examples_model_selection,\n",
        "    labels_train,\n",
        "    labels_model_selection,\n",
        ") = train_test_split(train_edges_for_checking, train_edges_solution, train_size=0.85, test_size=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3Xr-dK9siRq"
      },
      "source": [
        "batch_size = 512\n",
        "\n",
        "# link_features_train = link_examples_to_features(examples_train, data.numpy(), operator_concat)\n",
        "# print(link_features_train.shape)\n",
        "\n",
        "\n",
        "link_features_val = link_examples_to_features(examples_model_selection, data.numpy(), operator_concat)\n",
        "print(link_features_val.shape, sum(labels_model_selection))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKxk5_aOvitV",
        "outputId": "d88a586e-21ea-496d-e1ba-055b0ca2cb7b"
      },
      "source": [
        "labels_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 0, ..., 0, 0, 1])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSnYaTFtl24q"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "  'Characterizes a dataset for PyTorch'\n",
        "  def __init__(self, examples_train, labels_train, data):\n",
        "        'Initialization'\n",
        "        self.examples_train = examples_train\n",
        "        self.data = data\n",
        "\n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.examples_train)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        idx1,idx2 = self.examples_train[index]\n",
        "        X = torch.cat((data[:,idx1,:], data[:,idx2,:]), dim = 0)\n",
        "        Y = torch.clone(X)\n",
        "        for i in range(28):\n",
        "          if np.random.rand() < 0.3:\n",
        "            X[i,:] = 0\n",
        "        src_mask = torch.bernoulli(0.15*torch.ones(28,28))*(float('-inf'))\n",
        "        return X, Y, src_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvIGbaAVma9Q"
      },
      "source": [
        "training_set = Dataset(examples_train, labels_train, data)\n",
        "validation_set = Dataset(examples_model_selection, labels_model_selection, data)\n",
        "training_generator = torch.utils.data.DataLoader(training_set, shuffle = True, batch_size = 512)\n",
        "validation_generator = torch.utils.data.DataLoader(validation_set, shuffle = True, batch_size = 512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj-5HIyww6p-"
      },
      "source": [
        "num_steps = 10000\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,num_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "mAtq2K73xb7l",
        "outputId": "4c913c24-b2d8-4e54-d09c-47a7499bc68d"
      },
      "source": [
        "training_loss = torch.zeros(num_steps)\n",
        "test_auc = torch.zeros(num_steps//1000)\n",
        "for i in range(1,num_steps+1):\n",
        "  for X,y in training_generator:\n",
        "    X = X.to('cuda')\n",
        "    y = y.to('cuda')\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model(X)\n",
        "    loss = torch.nn.CrossEntropyLoss()(y_pred, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  scheduler.step()\n",
        "  with torch.no_grad():\n",
        "    training_loss[i-1] = loss\n",
        "    if i % 1000 == 0:\n",
        "      clear_output()\n",
        "      print(\"[%d/%d] Loss = %f\" % (i,num_steps,loss.item()))\n",
        "      y_pred = model(link_features_val).detach().cpu().softmax(dim = 1)\n",
        "      test_auc[i//1000 - 1] = roc_auc_score(labels_model_selection, y_pred[:,1].numpy())\n",
        "      print(test_auc[i//1000 - 1])\n",
        "      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-7a2d465853db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    119\u001b[0m                     \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                     eps=group['eps'])\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "oOCZKRalyIOF",
        "outputId": "9c078e60-c52c-4dd3-e45b-a545fbfb3eb7"
      },
      "source": [
        "plt.plot(training_loss[:13])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9564391290>]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFSCFZBIOJwm"
      },
      "source": [
        "model = model.to('cpu')\n",
        "y_pred = model(torch.tensor(link_features_val)).detach().cpu().softmax(dim = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h08153RU3FNs",
        "outputId": "86bb3ee3-80b6-4540-fb12-fc1e80f2906a"
      },
      "source": [
        "roc_auc_score(labels_model_selection, y_pred[:,1].numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(634465, 5888)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPii5yDn3Xmg"
      },
      "source": [
        "import pytorch_lightning as pl\n",
        "import math\n",
        "\n",
        "class MLP(pl.LightningModule):\n",
        "  def __init__(self, output_dim, input_dim = 128):\n",
        "    super().__init__()\n",
        "    self.mlp = torch.nn.Sequential(nn.Linear(input_dim, input_dim),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.Linear(input_dim, output_dim),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.Linear(output_dim,output_dim))\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.mlp(x)\n",
        "\n",
        "class Transformer(pl.LightningModule):\n",
        "  def __init__(self, output_size):\n",
        "    super().__init__()\n",
        "    self.positional = PositionalEncoding(128)\n",
        "    self.transformer = torch.nn.Transformer(d_model = 128, dropout = 0.1, batch_first = True, \n",
        "                                            num_encoder_layers = 3, num_decoder_layers = 3)\n",
        "\n",
        "  def forward(self, x, y, mask = None):\n",
        "    if mask != None:\n",
        "      x1 = self.transformer(self.positional(x), self.positional(y), src_mask = mask[0,:,:], tgt_mask = mask[0,:,:])\n",
        "    else:\n",
        "      x1 = self.transformer(self.positional(x), self.positional(y))\n",
        "    return x1\n",
        "\n",
        "  def training_step(self, train_batch, batch_idx):\n",
        "    X, Y, mask = train_batch\n",
        "    Y_pred = self.forward(X,X)\n",
        "    loss = torch.nn.functional.mse_loss(Y_pred,Y)\n",
        "    self.log(\"train_loss\", loss)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, validation_batch, batch_idx):\n",
        "    X, Y, mask = validation_batch\n",
        "    Y_pred = self.forward(X,X)\n",
        "    loss = torch.nn.functional.mse_loss(Y_pred,Y)\n",
        "    self.log(\"validation_loss\", loss)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.AdamW(self.parameters())\n",
        "    return optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXbQFKGPsiuP"
      },
      "source": [
        "class PositionalEncoding(pl.LightningModule):\n",
        "  def __init__(self, d_model, dropout=0.0, max_len=28):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    pe = torch.zeros(max_len, d_model)\n",
        "    position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "    pe[:, 0::2] = torch.sin(position * div_term)\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\n",
        "    pe = pe.unsqueeze(0)\n",
        "    self.register_buffer('pe', pe)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = x + self.pe[:x.size(1), :]\n",
        "    return self.dropout(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bU6f3Ucvb7e",
        "outputId": "039dd7a0-f912-4994-995e-ae768342d973"
      },
      "source": [
        "training_set = Dataset(examples_train, labels_train, data)\n",
        "validation_set = Dataset(examples_model_selection, labels_model_selection, data)\n",
        "training_generator = torch.utils.data.DataLoader(training_set, shuffle = True, batch_size = 256, num_workers = 4)\n",
        "validation_generator = torch.utils.data.DataLoader(validation_set, batch_size = 256, num_workers = 4)\n",
        "\n",
        "model = Transformer(128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "774529fa0ee744e6b39504440df958be",
            "6ae77d3998bf41919fdde0a6afdb2323",
            "d915287d2fa742389059fffeab010973",
            "bb8f72ff25504aa09b916d4525ceab6d",
            "658bcdf1c13a481991d346af63320c0f",
            "dd27cb56576545a8b5a43bc6f2f8d71d",
            "e2b468150f45450e97a9812a9eaac915",
            "65aa6394197e4ee18c4c23ded8d8713d",
            "bb07957144c14ef899cb42e19c9082c4",
            "3c460a5008ed4503b1476e512f6146d9",
            "49e2ef477bb94d0c95a500b035f37fad",
            "3723c3b7a7e341eea5b173145eb243dd",
            "f46c41f7a9a349cfb3b3b3b7f18fee92",
            "77f5954bdea34dac98806e160a086cad",
            "a4bc5d57a37442a183364968be2b4f0b",
            "501a107674994d7794ac3d70393da4e4",
            "e8dcec91701c4bacacb271db8b2efc7e",
            "d8e7fcf53bc046e0bc65097501fb5cd5",
            "cb83e8859bb040cbaf35cad2f9272ca0",
            "6ae22e3b85634edfa24be3200caa5143",
            "b860dd7038db43588ac20056e8cab1f7",
            "7c45dd7dac1d487f8e86cf46d1714020",
            "b9fa2b653c9641a2b2068ea6eb13fe41",
            "5a67842602b843e2be7f83f0ae87019f",
            "056d2a48b7054900b6cff5264aebfe75",
            "f1d137c0169648efa6c77ccd73271447",
            "ec66456ee1674eb994440c7a49869d96",
            "99165b64fa74474faa0c3b437f869530",
            "1c60e6b2bbbb4a859f3bc647bc878e8b",
            "459c4f79516c45b5b1d38342214fb5bb",
            "f52c9be7618e4ab7b93ecc7a3b5af181",
            "bd60f126d8a24780994ee2327c242e9c",
            "f79e364637ee4c6eaae92337003e8e91"
          ]
        },
        "id": "7mYwuRBWyJ4w",
        "outputId": "9e432c7f-14dd-45c6-ca91-edde9ef14712"
      },
      "source": [
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath='./drive/MyDrive/science4cast/Transformer-2/')\n",
        "\n",
        "trainer = pl.Trainer(gpus=1, \n",
        "                     default_root_dir='./drive/MyDrive/science4cast/Transformer-2/',\n",
        "                     max_epochs = 20,\n",
        "                     auto_lr_find='lr',\n",
        "                     callbacks = [checkpoint_callback])\n",
        "\n",
        "trainer.fit(model, training_generator, validation_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:446: UserWarning: Checkpoint directory ./drive/MyDrive/science4cast/Transformer-2/ exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name        | Type               | Params\n",
            "---------------------------------------------------\n",
            "0 | positional  | PositionalEncoding | 0     \n",
            "1 | transformer | Transformer        | 3.8 M \n",
            "---------------------------------------------------\n",
            "3.8 M     Trainable params\n",
            "0         Non-trainable params\n",
            "3.8 M     Total params\n",
            "15.030    Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "774529fa0ee744e6b39504440df958be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3723c3b7a7e341eea5b173145eb243dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: -1it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9fa2b653c9641a2b2068ea6eb13fe41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    if w.is_alive():\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "AssertionError: can only test a child process\n",
            "Traceback (most recent call last):\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    self._shutdown_workers()\n",
            "AssertionError: can only test a child process\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "    if w.is_alive():\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    if w.is_alive():\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "AssertionError: can only test a child process\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "    if w.is_alive():\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "Traceback (most recent call last):\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    if w.is_alive():\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "AssertionError: can only test a child process\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "Traceback (most recent call last):\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    if w.is_alive():\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "AssertionError: can only test a child process\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3d0eb48dd0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:1051: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQzy9QOL0s15"
      },
      "source": [
        "torch.save(model,\"./drive/MyDrive/science4cast/transformer-model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsI8erXk1JGU"
      },
      "source": [
        "class LP(pl.LightningModule):\n",
        "  def __init__(self, transformer, input_size = 28*128, output_dim = 2):\n",
        "    super().__init__()\n",
        "    self.transformer = transformer\n",
        "    self.mlp = MLP(output_dim, input_size)\n",
        "\n",
        "  def forward(self, x, y, mask = None):\n",
        "    if mask == None:\n",
        "      x1 = self.transformer(x,y)\n",
        "      y = self.mlp(torch.flatten(x1, start_dim = 1))\n",
        "    return y\n",
        "\n",
        "  def training_step(self, train_batch, batch_idx):\n",
        "    X, y = train_batch\n",
        "    y_pred = self.forward(X,X)\n",
        "    loss = torch.nn.CrossEntropyLoss()(y_pred, y)\n",
        "    self.log(\"train_loss\", loss)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, validation_batch, batch_idx):\n",
        "    X, y = validation_batch\n",
        "    y_pred = self.forward(X,X)\n",
        "    loss = torch.nn.CrossEntropyLoss()(y_pred, y)\n",
        "    self.log(\"validation_loss\", loss)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.AdamW(self.parameters())\n",
        "    return optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxex0TFe1Ki5"
      },
      "source": [
        "lp = LP(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFkU2V4b1Rqz"
      },
      "source": [
        "class DatasetLP(torch.utils.data.Dataset):\n",
        "  'Characterizes a dataset for PyTorch'\n",
        "  def __init__(self, examples_train, labels_train, data):\n",
        "        'Initialization'\n",
        "        self.examples_train = examples_train\n",
        "        self.data = data\n",
        "        self.labels = labels_train\n",
        "\n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.examples_train)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        idx1,idx2 = self.examples_train[index]\n",
        "        X = torch.cat((data[:,idx1,:], data[:,idx2,:]), dim = 0)\n",
        "        y = self.labels[index]\n",
        "        return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lz_Fpu6MyOFm",
        "outputId": "2bf7a5e5-1026-499d-9ec3-99162e634f4c"
      },
      "source": [
        "training_set = DatasetLP(examples_train, labels_train, data)\n",
        "validation_set = DatasetLP(examples_model_selection, labels_model_selection, data)\n",
        "training_generator = torch.utils.data.DataLoader(training_set, shuffle = True, batch_size = 256, num_workers = 4)\n",
        "validation_generator = torch.utils.data.DataLoader(validation_set, batch_size = 256, num_workers = 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 407,
          "referenced_widgets": [
            "efb3f33635a54f28a9cd8947210f8f5a",
            "9e3375cfea194ad48a473f12c798fe1a",
            "ebc75810ffc84f5cba8e6cd5598bdf11",
            "7d42c685f35f4917ad28bf499bdb63d8",
            "40b853bf5513414282bf5c9d599180d7",
            "a454d47191ce4487aebdb4cb72512739",
            "d81515bc787444d5a76367d3559ed8e3",
            "78178524012a47dc84388bfb85c86949",
            "c963ed6f20e446a7a8589d583a6c91d3",
            "34f6ae434fa144aa9cf73df5cd79b6fd",
            "99fda0044e9d4beca7a1f0384866c5fa",
            "811a3d97990b4c70b0cc2daa9fd1673c",
            "9d07023965d049279dc85c53d769ff84",
            "6b8f90d73d7941bb885da0697078fa5c",
            "74e2981ebe8f4044ab1bd11fcd3a163e",
            "19377f61581040ee82ee1c9958f94f43",
            "8073ff25fa0842e783570c215bb20024",
            "4a1ada1bf9154fe697e709f8382a940e",
            "1a1f215b18bd4f558a961121618e25ca",
            "5650909853124774beb69018d2c29c18",
            "8c844c8692a040cb9cd87e834305677e",
            "c2356fdb00674a5590bdb50c3d9e358a",
            "0997672b6d4144a09709713cc8ce3f2f"
          ]
        },
        "id": "5Go7qZ9tytYb",
        "outputId": "7e4a839b-1954-45b0-8cff-7d9d4d200b1f"
      },
      "source": [
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath='./drive/MyDrive/science4cast/TransformerLP-2/')\n",
        "\n",
        "trainer = pl.Trainer(gpus=1, \n",
        "                     default_root_dir='./drive/MyDrive/science4cast/TransformerLP-2/',\n",
        "                     max_epochs = 5,\n",
        "                     auto_lr_find='lr',\n",
        "                     callbacks = [checkpoint_callback])\n",
        "\n",
        "trainer.fit(lp, training_generator, validation_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:446: UserWarning: Checkpoint directory ./drive/MyDrive/science4cast/TransformerLP-2/ exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name        | Type        | Params\n",
            "--------------------------------------------\n",
            "0 | transformer | Transformer | 3.8 M \n",
            "1 | mlp         | MLP         | 12.9 M\n",
            "--------------------------------------------\n",
            "16.6 M    Trainable params\n",
            "0         Non-trainable params\n",
            "16.6 M    Total params\n",
            "66.454    Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efb3f33635a54f28a9cd8947210f8f5a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "811a3d97990b4c70b0cc2daa9fd1673c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: -1it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0997672b6d4144a09709713cc8ce3f2f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsutTp7fSS2Q"
      },
      "source": [
        "lp = LP.load_from_checkpoint('/content/drive/MyDrive/science4cast/TransformerLP2/epoch=49-step=702249.ckpt', transformer = model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tOgDZxOUOfo"
      },
      "source": [
        "test_set = DatasetLP(unconnected_vertex_pairs, torch.zeros(len(unconnected_vertex_pairs)), data)\n",
        "test_generator = torch.utils.data.DataLoader(test_set, batch_size = 512, num_workers = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0K8mgvkyzkL",
        "outputId": "f3e9cecc-624b-468c-ec69-c8057d495398"
      },
      "source": [
        "predictions = torch.zeros(len(unconnected_vertex_pairs), 2)\n",
        "batch_size = 512\n",
        "idx = 0\n",
        "for X, y in tqdm(test_generator):\n",
        "  predictions[idx*batch_size:(idx+1)*batch_size,:] = lp(X,X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 8/1954 [00:20<1:35:55,  2.96s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2GhwPiNfYUR"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EI8QlcIeQ_Qn"
      },
      "source": [
        "%%capture\n",
        "!pip install pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5614OXpmVFR7",
        "outputId": "a37d998d-2215-478f-af0a-5ae4be990495"
      },
      "source": [
        "%pip install -q stellargraph[demos]==1.2.1\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive', force_remount = True)\n",
        "DRIVE_PATH = \"/content/drive/My Drive/science4cast\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5m81FeDVHXA"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from math import isclose\n",
        "from scipy import sparse\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "from datetime import date\n",
        "from collections import Counter\n",
        "import multiprocessing\n",
        "from IPython.display import display, HTML\n",
        "from sklearn.model_selection import train_test_split\n",
        "import stellargraph as sg\n",
        "from stellargraph import StellarGraph, datasets\n",
        "from stellargraph.data import EdgeSplitter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6Asoq3zVJRH",
        "outputId": "eadf1c6a-634b-46c6-de2c-92c95ca0629d"
      },
      "source": [
        "NUM_OF_VERTICES=64719 # number of vertices of the semantic net\n",
        "DRIVE_PATH = \"/content/drive/My Drive/science4cast\"\n",
        "data_source = os.path.join(DRIVE_PATH, 'competition_data/CompetitionSet2017_3.pkl')\n",
        "#data_source = os.path.join(DRIVE_PATH, 'TrainSet2014_3.pkl')\n",
        "full_dynamic_graph_sparse,unconnected_vertex_pairs,year_start,years_delta = pickle.load( open( data_source, \"rb\" ) )\n",
        "\n",
        "print(data_source+' has '+str(len(full_dynamic_graph_sparse))+' edges between a total of '+str(NUM_OF_VERTICES)+ ' vertices.\\n\\n')\n",
        "print('The goal is to predict which of '+str(len(unconnected_vertex_pairs))+' unconnectedvertex-pairs\\nin unconnected_vertex_pairs will be connected until '+str(year_start+years_delta)+'.')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/science4cast/competition_data/CompetitionSet2017_3.pkl has 7652945 edges between a total of 64719 vertices.\n",
            "\n",
            "\n",
            "The goal is to predict which of 1000000 unconnectedvertex-pairs\n",
            "in unconnected_vertex_pairs will be connected until 2020.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEhkRygVVmtn"
      },
      "source": [
        "# Helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15TNVAJlVOge"
      },
      "source": [
        "def create_training_data(full_graph,year_start,years_delta,edges_used=500000,vertex_degree_cutoff=10):\n",
        "    \"\"\"\n",
        "    :param full_graph: Full graph, numpy array dim(n,3) [vertex 1, vertex 2, time stamp]\n",
        "    :param year_start: year of graph\n",
        "    :param years_delta: distance for prediction in years (prediction on graph of year_start+years_delta)\n",
        "    :param edges_used: optional filter to create a random subset of edges for rapid prototyping (default: 500,000)\n",
        "    :param vertex_degree_cutoff: optional filter, for vertices in training set having a minimal degree of at least vertex_degree_cutoff  (default: 10)\n",
        "    :return:\n",
        "\n",
        "    all_edge_list: graph of year_start, numpy array dim(n,2)\n",
        "    unconnected_vertex_pairs: potential edges for year_start+years_delta\n",
        "    unconnected_vertex_pairs_solution: numpy array with integers (0=unconnected, 1=connected), solution, length = len(unconnected_vertex_pairs)\n",
        "    \"\"\"\n",
        "\n",
        "    years=[year_start,year_start+years_delta]    \n",
        "    print(years)\n",
        "    day_origin = date(1990,1,1)\n",
        "    \n",
        "    days_curr = (date(year_start,12,31)-day_origin).days\n",
        "    days_later = (date(year_start+years_delta,12,31)-day_origin).days\n",
        "\n",
        "    all_G = []\n",
        "\n",
        "    for days in [days_later, days_curr]:\n",
        "      all_edges=full_graph[full_graph[:,2]<=days]\n",
        "      print('    num of edges: ', len(all_edges))\n",
        "      adj_mat_sparse = sparse.csr_matrix((np.ones(len(all_edges)), (all_edges[:,0], all_edges[:,1])), shape=(NUM_OF_VERTICES,NUM_OF_VERTICES))\n",
        "      all_G.append(nx.from_scipy_sparse_matrix(adj_mat_sparse, parallel_edges=False, create_using=None, edge_attribute='weight'))\n",
        "\n",
        "    all_degs=np.array(adj_mat_sparse.sum(0))[0]\n",
        "\n",
        "    ## Create all edges to be predicted\n",
        "    all_vertices=np.array(range(NUM_OF_VERTICES))\n",
        "    vertex_large_degs=all_vertices[all_degs>=vertex_degree_cutoff] # use only vertices with degrees larger than 10.\n",
        "\n",
        "    ## get positive examples\n",
        "    all_edges_after = full_graph[(days_curr<full_graph[:,2]) & (full_graph[:,2]<=days_later)]\n",
        "    print(len(all_edges_after))\n",
        "    all_edges_after = all_edges_after[np.all(np.isin(all_edges_after[:,:2], vertex_large_degs), axis=1)]\n",
        "    print(len(all_edges_after))\n",
        "\n",
        "    ## get negative  examples\n",
        "    unconnected_vertex_pairs=[]\n",
        "\n",
        "    while len(unconnected_vertex_pairs) < max(edges_used, len(all_edges_after)):        \n",
        "        v1,v2=np.random.choice(vertex_large_degs, 2)\n",
        "\n",
        "        if (v1!=v2) and (not all_G[0].has_edge(v1,v2)) and (not all_G[1].has_edge(v1,v2)):\n",
        "            unconnected_vertex_pairs.append((v1,v2))\n",
        "\n",
        "    unconnected_vertex_pairs_solution=np.array([1]*len(all_edges_after)+[0]*len(unconnected_vertex_pairs))        \n",
        "    unconnected_vertex_pairs=np.vstack((all_edges_after[:, :2], np.array(unconnected_vertex_pairs)))\n",
        "  \n",
        "    print('Number of unconnected vertex pairs for prediction: ', len(unconnected_vertex_pairs_solution))\n",
        "    print('Number of vertex pairs that will be connected: ' , sum(unconnected_vertex_pairs_solution))\n",
        "    print('Ratio of vertex pairs that will be connected: ' , sum(unconnected_vertex_pairs_solution)/len(unconnected_vertex_pairs_solution))\n",
        "      \n",
        "    return np.array(all_edges), unconnected_vertex_pairs, unconnected_vertex_pairs_solution\n",
        "\n",
        "edges_used=1*10**6 # Best would be to use all vertices, to create more training data. But that takes long and requires huge amount of memory. So here we use a random subset.\n",
        "vertex_degree_cutoff=10\n",
        "\n",
        "def procrustes(X, Y, scaling=True, reflection='best'):\n",
        "    \"\"\"\n",
        "    A port of MATLAB's `procrustes` function to Numpy.\n",
        "\n",
        "    Procrustes analysis determines a linear transformation (translation,\n",
        "    reflection, orthogonal rotation and scaling) of the points in Y to best\n",
        "    conform them to the points in matrix X, using the sum of squared errors\n",
        "    as the goodness of fit criterion.\n",
        "\n",
        "        d, Z, [tform] = procrustes(X, Y)\n",
        "\n",
        "    Inputs:\n",
        "    ------------\n",
        "    X, Y    \n",
        "        matrices of target and input coordinates. they must have equal\n",
        "        numbers of  points (rows), but Y may have fewer dimensions\n",
        "        (columns) than X.\n",
        "\n",
        "    scaling \n",
        "        if False, the scaling component of the transformation is forced\n",
        "        to 1\n",
        "\n",
        "    reflection\n",
        "        if 'best' (default), the transformation solution may or may not\n",
        "        include a reflection component, depending on which fits the data\n",
        "        best. setting reflection to True or False forces a solution with\n",
        "        reflection or no reflection respectively.\n",
        "\n",
        "    Outputs\n",
        "    ------------\n",
        "    d       \n",
        "        the residual sum of squared errors, normalized according to a\n",
        "        measure of the scale of X, ((X - X.mean(0))**2).sum()\n",
        "\n",
        "    Z\n",
        "        the matrix of transformed Y-values\n",
        "\n",
        "    tform   \n",
        "        a dict specifying the rotation, translation and scaling that\n",
        "        maps X --> Y\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    n,m = X.shape\n",
        "    ny,my = Y.shape\n",
        "\n",
        "    muX = X.mean(0)\n",
        "    muY = Y.mean(0)\n",
        "\n",
        "    X0 = X - muX\n",
        "    Y0 = Y - muY\n",
        "\n",
        "    ssX = (X0**2.).sum()\n",
        "    ssY = (Y0**2.).sum()\n",
        "\n",
        "    # centred Frobenius norm\n",
        "    normX = np.sqrt(ssX)\n",
        "    normY = np.sqrt(ssY)\n",
        "\n",
        "    # scale to equal (unit) norm\n",
        "    X0 /= normX\n",
        "    Y0 /= normY\n",
        "\n",
        "    if my < m:\n",
        "        Y0 = np.concatenate((Y0, np.zeros(n, m-my)),0)\n",
        "\n",
        "    # optimum rotation matrix of Y\n",
        "    A = np.dot(X0.T, Y0)\n",
        "    U,s,Vt = np.linalg.svd(A,full_matrices=False)\n",
        "    V = Vt.T\n",
        "    T = np.dot(V, U.T)\n",
        "\n",
        "    if reflection != 'best':\n",
        "\n",
        "        # does the current solution use a reflection?\n",
        "        have_reflection = np.linalg.det(T) < 0\n",
        "\n",
        "        # if that's not what was specified, force another reflection\n",
        "        if reflection != have_reflection:\n",
        "            V[:,-1] *= -1\n",
        "            s[-1] *= -1\n",
        "            T = np.dot(V, U.T)\n",
        "\n",
        "    traceTA = s.sum()\n",
        "\n",
        "    if scaling:\n",
        "\n",
        "        # optimum scaling of Y\n",
        "        b = traceTA * normX / normY\n",
        "\n",
        "        # standarised distance between X and b*Y*T + c\n",
        "        d = 1 - traceTA**2\n",
        "\n",
        "        # transformed coords\n",
        "        Z = normX*traceTA*np.dot(Y0, T) + muX\n",
        "\n",
        "    else:\n",
        "        b = 1\n",
        "        d = 1 + ssY/ssX - 2 * traceTA * normY / normX\n",
        "        Z = normY*np.dot(Y0, T) + muX\n",
        "\n",
        "    # transformation matrix\n",
        "    if my < m:\n",
        "        T = T[:my,:]\n",
        "    c = muX - b*np.dot(muY, T)\n",
        "    \n",
        "    #transformation values \n",
        "    tform = {'rotation':T, 'scale':b, 'translation':c}\n",
        "   \n",
        "    return d, Z, tform\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# 1. link embeddings\n",
        "def link_examples_to_features(link_examples, embedding, binary_operator):\n",
        "    return binary_operator(embedding[link_examples[:,0]], embedding[link_examples[:,1]])\n",
        "\n",
        "# 2. training classifier\n",
        "def train_link_prediction_model(link_examples, link_labels, get_embedding, binary_operator):\n",
        "    clf = link_prediction_classifier()\n",
        "    link_features = link_examples_to_features(\n",
        "        link_examples, get_embedding, binary_operator\n",
        "    )\n",
        "    clf.fit(link_features, link_labels)\n",
        "    return clf\n",
        "\n",
        "\n",
        "def link_prediction_classifier(max_iter=5000):\n",
        "    lr_clf = LogisticRegressionCV(Cs=10, cv=5, scoring=\"roc_auc\", max_iter=max_iter)\n",
        "    return Pipeline(steps=[(\"sc\", StandardScaler()), (\"clf\", lr_clf)])\n",
        "\n",
        "\n",
        "# 3. and 4. evaluate classifier\n",
        "def evaluate_link_prediction_model(clf, link_examples_test, link_labels_test, get_embedding, binary_operator):\n",
        "    link_features_test = link_examples_to_features(\n",
        "        link_examples_test, get_embedding, binary_operator\n",
        "    )\n",
        "    score = evaluate_roc_auc(clf, link_features_test, link_labels_test)\n",
        "    return score\n",
        "\n",
        "\n",
        "def evaluate_roc_auc(clf, link_features, link_labels):\n",
        "    predicted = clf.predict_proba(link_features)\n",
        "\n",
        "    # check which class corresponds to positive links\n",
        "    positive_column = list(clf.classes_).index(1)\n",
        "    return roc_auc_score(link_labels, predicted[:, positive_column])\n",
        "\n",
        "def operator_hadamard(u, v):\n",
        "    return u * v\n",
        "\n",
        "\n",
        "def operator_l1(u, v):\n",
        "    return np.abs(u - v)\n",
        "\n",
        "\n",
        "def operator_l2(u, v):\n",
        "    return (u - v) ** 2\n",
        "\n",
        "\n",
        "def operator_avg(u, v):\n",
        "    return (u + v) / 2.0\n",
        "\n",
        "def operator_concat(u,v):\n",
        "    return np.hstack((u,v))\n",
        "\n",
        "\n",
        "def run_link_prediction(binary_operator, embedding_train):\n",
        "    clf = train_link_prediction_model(\n",
        "        examples_train, labels_train, embedding_train, binary_operator\n",
        "    )\n",
        "    score = evaluate_link_prediction_model(\n",
        "        clf,\n",
        "        examples_model_selection,\n",
        "        labels_model_selection,\n",
        "        embedding_train,\n",
        "        binary_operator,\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"classifier\": clf,\n",
        "        \"binary_operator\": binary_operator,\n",
        "        \"score\": score,\n",
        "        \"embedding\": embedding_train,\n",
        "    }\n",
        "\n",
        "#binary_operators = [operator_hadamard, operator_l1, operator_l2, operator_avg]\n",
        "binary_operators = [operator_l2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2zbifr1VpGg"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G93sRc4VTyJ"
      },
      "source": [
        "embeddings = []\n",
        "year_start = 1994\n",
        "num_years = 23\n",
        "for i in range(num_years):\n",
        "  year = i+year_start\n",
        "  name = 'node2vec-'+str(year) +'.pkl'\n",
        "  with open(\"/content/drive/MyDrive/science4cast/node2vec_embeddings/\"+name, \"rb\") as pickle_file:\n",
        "    embeddings = embeddings + [pickle.load(pickle_file)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYt3fu7gVhKt"
      },
      "source": [
        "aligned_embeddings = []\n",
        "num_years = 23\n",
        "for i in range(num_years):\n",
        "  d,Z,tform = procrustes(embeddings[-1], embeddings[i])\n",
        "  aligned_embeddings = aligned_embeddings + [Z]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdcoTp97VlGR"
      },
      "source": [
        "num_nodes,embed_dim = aligned_embeddings[0].shape\n",
        "data = torch.zeros(num_years, num_nodes, embed_dim) #torch.tensor(aligned_embeddings[0])\n",
        "for i in range(num_years):\n",
        "  data[i,:,:] = torch.tensor(aligned_embeddings[i]) #torch.cat((data,torch.tensor(aligned_embeddings[i])), dim = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qq7vEo7VupC"
      },
      "source": [
        "embeddings = 0\n",
        "aligned_embeddings = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQiFS3H8Vw4L"
      },
      "source": [
        "import pytorch_lightning as pl\n",
        "import math\n",
        "\n",
        "class MLP(pl.LightningModule):\n",
        "  def __init__(self, output_dim, input_dim = 128):\n",
        "    super().__init__()\n",
        "    self.mlp = torch.nn.Sequential(nn.Linear(input_dim, input_dim),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.Linear(input_dim, output_dim),\n",
        "                                   nn.ReLU(),\n",
        "                                   nn.Linear(output_dim,output_dim))\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.mlp(x)\n",
        "\n",
        "class Transformer(pl.LightningModule):\n",
        "  def __init__(self, output_size):\n",
        "    super().__init__()\n",
        "    self.positional = PositionalEncoding(128)\n",
        "    self.transformer = torch.nn.Transformer(d_model = 128, dropout = 0.1, batch_first = True, \n",
        "                                            num_encoder_layers = 3, num_decoder_layers = 3)\n",
        "\n",
        "  def forward(self, x, y, mask = None):\n",
        "    if mask != None:\n",
        "      x1 = self.transformer(self.positional(x), self.positional(y), src_mask = mask[0,:,:], tgt_mask = mask[0,:,:])\n",
        "    else:\n",
        "      x1 = self.transformer(self.positional(x), self.positional(y))\n",
        "    return x1\n",
        "\n",
        "  def training_step(self, train_batch, batch_idx):\n",
        "    X, Y, mask = train_batch\n",
        "    Y_pred = self.forward(X,X)\n",
        "    loss = torch.nn.functional.mse_loss(Y_pred,Y)\n",
        "    self.log(\"train_loss\", loss)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, validation_batch, batch_idx):\n",
        "    X, Y, mask = validation_batch\n",
        "    Y_pred = self.forward(X,X)\n",
        "    loss = torch.nn.functional.mse_loss(Y_pred,Y)\n",
        "    self.log(\"validation_loss\", loss)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.AdamW(self.parameters())\n",
        "    return optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it4voN2fV0Yk"
      },
      "source": [
        "class PositionalEncoding(pl.LightningModule):\n",
        "  def __init__(self, d_model, dropout=0.0, max_len=46):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    pe = torch.zeros(max_len, d_model)\n",
        "    position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "    pe[:, 0::2] = torch.sin(position * div_term)\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\n",
        "    pe = pe.unsqueeze(0)\n",
        "    self.register_buffer('pe', pe)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = x + self.pe[:x.size(1), :]\n",
        "    return self.dropout(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQsfjeqjV3J9"
      },
      "source": [
        "class LP(pl.LightningModule):\n",
        "  def __init__(self, transformer, input_size = 46*128, output_dim = 2):\n",
        "    super().__init__()\n",
        "    self.transformer = transformer\n",
        "    self.mlp = MLP(output_dim, input_size)\n",
        "\n",
        "  def forward(self, x, y, mask = None):\n",
        "    if mask == None:\n",
        "      x1 = self.transformer(x,y)\n",
        "      y = self.mlp(torch.flatten(x1, start_dim = 1))\n",
        "    return y\n",
        "\n",
        "  def training_step(self, train_batch, batch_idx):\n",
        "    X, y = train_batch\n",
        "    y_pred = self.forward(X,X)\n",
        "    loss = torch.nn.CrossEntropyLoss()(y_pred, y)\n",
        "    self.log(\"train_loss\", loss)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, validation_batch, batch_idx):\n",
        "    X, y = validation_batch\n",
        "    y_pred = self.forward(X,X)\n",
        "    loss = torch.nn.CrossEntropyLoss()(y_pred, y)\n",
        "    self.log(\"validation_loss\", loss)\n",
        "\n",
        "  def test_step(self, test_batch, batch_idx):\n",
        "    X, y = test_batch\n",
        "    y_pred = self.forward(X,X)\n",
        "    torch.save(y_pred, \"./drive/MyDrive/science4cast/TransformerLP/\"+str(batch_idx))\n",
        "    \n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.AdamW(self.parameters())\n",
        "    return optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enWKiiNlV7Qj"
      },
      "source": [
        "class DatasetLP(torch.utils.data.Dataset):\n",
        "  'Characterizes a dataset for PyTorch'\n",
        "  def __init__(self, examples_train, labels_train, data):\n",
        "        'Initialization'\n",
        "        self.examples_train = examples_train\n",
        "        self.data = data\n",
        "        self.labels = labels_train\n",
        "\n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.examples_train)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        idx1,idx2 = self.examples_train[index]\n",
        "        X = torch.cat((data[:,idx1,:], data[:,idx2,:]), dim = 0)\n",
        "        y = self.labels[index]\n",
        "        return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c0zqmCqV-JG"
      },
      "source": [
        "model = Transformer(128)\n",
        "lp = LP.load_from_checkpoint('/content/drive/MyDrive/science4cast/TransformerLP2/epoch=49-step=702249.ckpt', transformer = model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-_heMcfWKNP"
      },
      "source": [
        "test_set = DatasetLP(unconnected_vertex_pairs, torch.zeros(len(unconnected_vertex_pairs)), data)\n",
        "test_generator = torch.utils.data.DataLoader(test_set, batch_size = 512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xtVuKiFWPQb"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256,
          "referenced_widgets": [
            "8c8e1b931ddc49b894de4ab4162e38a7",
            "85fbe4274192478e9a79aa472a6b09a6",
            "4116aabe3f564f468027605ff38364e6",
            "64d58fbf0c25439e8dd7e9c6b7f9c290",
            "2e119d682bef41a1875cf178a781906f",
            "bc7c121f658e4e10bec3f805524412f0",
            "c99433c527c1413a852b5fbf1b8585bc",
            "bedd58b7248f40eb905924ad1ed46e63",
            "6438c367f8214d808af32e99f12678ef",
            "56f1b30ef6fc45a396a4733a61bb2cb6",
            "a0d0b4dfc1c9492dbb05aae46c4dc74f"
          ]
        },
        "id": "I3BQVSj-WYw1",
        "outputId": "bb001541-8448-46f4-f7dd-1f16d045d28b"
      },
      "source": [
        "trainer = pl.Trainer(gpus=1)\n",
        "trainer.test(lp, test_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:106: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c8e1b931ddc49b894de4ab4162e38a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXGE2GM9a6NF"
      },
      "source": [
        "predictions = torch.zeros(len(unconnected_vertex_pairs), 2)\n",
        "a = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu50W87WWBj2"
      },
      "source": [
        "predictions = torch.zeros(len(unconnected_vertex_pairs), 2)\n",
        "batch_size = 512\n",
        "for i in range(1954):\n",
        "  if i < 1953:\n",
        "    predictions[i*batch_size:(i+1)*batch_size,:] = torch.load(\"./drive/MyDrive/science4cast/TransformerLP/\"+str(i))\n",
        "  else:\n",
        "    predictions[i*batch_size:,:] = torch.load(\"./drive/MyDrive/science4cast/TransformerLP/\"+str(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awUeqPg7eIkj"
      },
      "source": [
        "predictions = predictions.softmax(dim = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCMA3cF5fXPJ"
      },
      "source": [
        "all_predictions_eval = predictions[:,1].numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joueqh6-gd76"
      },
      "source": [
        "sorted_predictions_eval=np.flip(np.argsort(all_predictions_eval,axis=0))  \n",
        "year_start = 2017"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3gxfGnxgyHh",
        "outputId": "92526549-097f-43a8-9fca-547e53b82eac"
      },
      "source": [
        "import json\n",
        "\n",
        "if year_start==2017:\n",
        "    # Save the results for submission.\n",
        "    submit_file=\"./drive/MyDrive/science4cast/transformer_all_idx\"+str(year_start)+\"_\"+str(years_delta)+\".json\"\n",
        "    all_idx_list_float=list(map(float, sorted_predictions_eval))\n",
        "    with open(submit_file, \"w\", encoding=\"utf8\") as json_file:\n",
        "        json.dump(all_idx_list_float, json_file)\n",
        "    \n",
        "    print(\"Solution stored as \"+submit_file+\".\\nLooking forward to your submission.\")  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Solution stored as ./drive/MyDrive/science4cast/transformer_all_idx2017_3.json.\n",
            "Looking forward to your submission.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tJWFvevg0_H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
